---
title: "Data can be a Drag!"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)
library(dragracer)
library(glue)
library(here)
library(flexdashboard)
library(googlesheets4)
source(here("Functions","db_helper_functions.R"))
```

# Data Sources

### dragraceR

-   This is a cool library a friend of mine Jessica ([github](https://github.com/jalavery), [twitter](https://twitter.com/jessicalavs)) came across, containing three data sets:

    1.  rpdr_contep: Contestant performance at the Episode level

    2.  rpdr_ep: Episode level

    3.  rpdr_contestants: Contestant level

### [Data for Progress](https://www.dataforprogress.org/)

-   A Progressive policy and polling organization. They ran a contest that challenged teams to build a model to accurately predict the winner and loser of each episode. This is outside the scope of my project.

-   They gathered [data](https://docs.google.com/spreadsheets/d/1Sotvl3o7J_ckKUg5sRiZTqNQn3hPqhepBSeOpMTK15Q/edit#gid=228427306) through season 10 and made it publicly available:

    1.  all_episodes: Episode Level

    2.  all_contestants: Contestant Level

    3.  all_rankings: Ranking of each contestant in each episode

    4.  all_social_media: Scrape of contestants social media follower counts (not complete)

# Motivation

-   The data sources above complement each other. I will use them to demonstrate my ETL skills.

-   By the letter:

    -   **E :** Extract data from a library (not difficult) and googleSheets

    -   **T :** Transform during the extraction and follow a data model that allows for joining

    -   **L :** Load the final dataframes into and RSQLite database

-   I have significant experience in database management and will be creating an RSQLite database that will be stored in this repository. I chose this route over using AWS because this project will be converted into a library.

    -   If this weren't open source I would write all data into S3 and load into Redshift database

# Goals for next iteration

-   Scrape the[DragRace WiKi](https://rupaulsdragrace.fandom.com/wiki/RuPaul%27s_Drag_Race_Wiki) for drag families, exit quotes and other

![](https://64.media.tumblr.com/d016d4a5a6ca854cc186bcc1fe70c0e9/db754f152e7389c3-9b/s500x750/f7dbb99134b1dfa6e475c290dcb61202e1b4c5f1.gifv)

### DragRacer Cleaning

-   RSQLite is a little funky when it comes to dates, for some reason they need to be stored as characters. Will be using as.character and as_date to transform all date columns

```{r load data from dragracer and transform columns, echo=FALSE, include=FALSE}
drag_racer_contestants <- rpdr_contestants %>% 
  mutate_at(c("dob"),as.character)

drag_racer_episodes <- rpdr_ep%>% 
  mutate_at(c("airdate"),as.character)

drag_racer_combined <- rpdr_contep
```

### Data For Progress Scrape and Clean, Queen

-   Using the googledrive4 library to pull in the data

-   **VERY IMPORTANT:** This data is coming from an open source Google sheet, users need to turn Google authentication off.Â 

-   I needed to clean up some of the column types so they were compatible with r data types.

    -   all_social_media's first observation went against the data types of the rest of the rows... embarrassed how long it took me to figure this bug out. PUT A SHADY SOMETHING HERE.

-   Check out the [Column Specification](https://googlesheets4.tidyverse.org/reference/range_read.html) section. We don't transform columns like we would reader, a single string for all columns is required... which is annoying but I'll give them a pass because of how easy they've made it!

-   For good measure, I am going to trim leading and trailing white space with the trim_ws argument... werk smarter, harder!

```{r Scrape data from Google sheets and rename columns, echo=FALSE, include=FALSE}
googlesheets4::gs4_deauth() 
data_for_prog_url <- "https://docs.google.com/spreadsheets/d/1Sotvl3o7J_ckKUg5sRiZTqNQn3hPqhepBSeOpMTK15Q/"

# RSLite() is weird with dates and we need to store them as characters. Will use a simple mutate

all_episodes <-  read_sheet(data_for_prog_url, sheet="all_episodes", col_names=TRUE
                            , col_types='ccDccc', trim_ws=TRUE) %>% 
  mutate_at(c("episode_airdate"), as.character)

all_contestants <-read_sheet(data_for_prog_url, sheet="all_contestants", col_names=TRUE
                             , col_types='cccciccicc',  trim_ws=TRUE)

all_rankings <- read_sheet(data_for_prog_url, sheet="all_rankings", col_names=TRUE
                           , col_types='cccc', trim_ws=TRUE)

# Skipping the headers, it is easier to ordinally rename
# applying the same mutate for the date column
all_social_media <- read_sheet(data_for_prog_url, sheet="all_social_media", col_names=FALSE
                               , col_types='cDii',trim_ws=TRUE, skip=1)%>% 
  rename(  contestant_id=1
         , date_pulled=2
         , twitter_followers=3
         , instagram_followers=4
         )%>% 
  mutate_at(c("date_pulled"), as.character)
                              

```
