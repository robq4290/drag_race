---
title: "Data can be a Drag!"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) 
library(DBI)
library(dragracer)
library(glue)
library(here)
library(flexdashboard)
library(googlesheets4)
library(miceadds)
library(rvest)
library(dm)
library(stringr)
#source(here("Functions","db_helper_functions.R"))
# Default file type is .R  if different need to sepcify
source.all(here("Functions"))
```

# Data Sources

### dragraceR

-   This is a cool library a friend of mine Jessica ([github](https://github.com/jalavery), [twitter](https://twitter.com/jessicalavs)) came across, containing three data sets:

    1.  rpdr_contep: Contestant performance at the Episode level

    2.  rpdr_ep: Episode level

    3.  rpdr_contestants: Contestant level

### [Data for Progress](https://www.dataforprogress.org/)

-   A Progressive policy and polling organization. They ran a contest that challenged teams to build a model to accurately predict the winner and loser of each episode. This is outside the scope of my project.

-   They gathered [data](https://docs.google.com/spreadsheets/d/1Sotvl3o7J_ckKUg5sRiZTqNQn3hPqhepBSeOpMTK15Q/edit#gid=228427306) through season 10 and made it publicly available:

    1.  all_episodes: Episode Level

    2.  all_contestants: Contestant Level

    3.  all_rankings: Ranking of each contestant in each episode

    4.  all_social_media: Scrape of contestants social media follower counts (not complete)

# Motivation

-   The data sources above complement each other. I will use them to demonstrate my ETL skills.

-   By the letter:

    -   **E :** Extract data from a library (not difficult) and googleSheets

    -   **T :** Transform during the extraction and follow a data model that allows for joining

    -   **L :** Load the final dataframes into and RSQLite database

-   I have significant experience in database management and will be creating an RSQLite database that will be stored in this repository. I chose this route over using AWS because this project will be converted into a library.

    -   If this weren't open source I would write all data into S3 and load into Redshift database

# Goals for next iteration

-   Scrape the[DragRace WiKi](https://rupaulsdragrace.fandom.com/wiki/RuPaul%27s_Drag_Race_Wiki) for drag families, exit quotes and other

![](https://64.media.tumblr.com/d016d4a5a6ca854cc186bcc1fe70c0e9/db754f152e7389c3-9b/s500x750/f7dbb99134b1dfa6e475c290dcb61202e1b4c5f1.gifv)

### DragRacer Cleaning

-   RSQLite is a little funky when it comes to dates, for some reason they need to be stored as characters. Will be using as.character and as_date to transform all date columns

```{r load data from dragracer and transform columns, echo=FALSE, include=FALSE}
drag_racer_contestants <- rpdr_contestants %>% 
  mutate_at(c("dob"),as.character)

drag_racer_episodes <- rpdr_ep%>% 
  mutate_at(c("airdate"),as.character)

drag_racer_combined <- rpdr_contep
```

### Data For Progress Scrape and Clean, Queen

-   Using the googledrive4 library to pull in the data

-   **VERY IMPORTANT:** This data is coming from an open source Google sheet, users need to turn Google authentication off.Â 

-   I needed to clean up some of the column types so they were compatible with r data types.

    -   all_social_media's first observation went against the data types of the rest of the rows... embarrassed how long it took me to figure this bug out. PUT A SHADY SOMETHING HERE.

-   Check out the [Column Specification](https://googlesheets4.tidyverse.org/reference/range_read.html) section. We don't transform columns like we would reader, a single string for all columns is required... which is annoying but I'll give them a pass because of how easy they've made it!

-   For good measure, I am going to trim leading and trailing white space with the trim_ws argument... werk smarter, harder!

-   This can be computationally expensive, I am going to save the data frames and then turn this chunk into a function- don't want this chunk unnecessarily running. Please see get_dfp_frames in the data_cleaning_functions.R script. \*\* Add a link to this so the users can jump to see the source code

```{r Read Flat files or scrape from google, echo=FALSE, include=FALSE}
frame_list <- c("all_episodes", "all_contestants", "all_rankings", "all_social_media")

# can probably replace this with miceadds::load.files()
for(df in frame_list){
 
  rds_name <- glue("{df}.RDS")
  file_loc <- here("Input",rds_name)
  
  if(file.exists(file_loc)){
    assign(df,readRDS(file_loc))
    final_logic <- T
  }else{
    print(glue("{file_loc} does not exist"))
    final_logic <- F
  }
  
}
if(!final_logic){
  get_dfp_frames(frame_list=frame_list, save_path=here("Input"))
}
```

```{r scrape drag race wiki, echo=FALSE, include=FALSE }

drag_wiki_data <- get_drag_family_data()
```

```{r get the elements from the data scraping list and save, echo=FALSE, include=FALSE}

drag_family_data <- drag_wiki_data$drag_family_connections

drag_family_scrape <- drag_wiki_data$drag_house_frame

rm(drag_wiki_data)
```

```{r write scrape tables to database, echo=FALSE, include=FLASE}
# use this chunk to get the data model together with the dm libary

rpdr_conn <- DBI::dbConnect(RSQLite::SQLite(), dbname="rpdr.sqlite")

#rpdr_table_map <- dm::dm_from_src(rpdr_conn)

DBI::dbWriteTable(conn=rpdr_conn, name="drag_family_scrape", value=drag_family_scrape, append=TRUE, row.names=FALSE)
DBI::dbWriteTable(conn=rpdr_conn, name="drag_family", value=drag_family_data, append=TRUE, row.names=FALSE)

DBI::dbDisconnect(rpdr_conn)
```

# Key Column Transformations
```{r changing column types and names for clarity, echo=FALSE, include=FALSE }
cntstnts <- drag_racer_contestants %>% 
  mutate(   season=stringr::str_remove(season,"S")
           ,season=stringr::str_remove(season,"^0") # need to clean this regex up
         ) %>% 
  separate(hometown,c("City","State"),",")
```


### Data Model after everything is transformed

Ideally, I would be able to use primary and foreign keys in a database... but I 
don't have one set up (that is for the next iteration) and the RSQLite() in memory
doesn't seem to remember the pks I assigned. 
[Data Model Reference](https://cynkra.github.io/dm/articles/howto-dm-df.html)

```{r create a data model from frames, echo=FALSE, include=FALSE}
data_model_no_keys <- dm::dm(all_contestants, all_episodes, all_rankings, all_social_media, drag_racer_combined, drag_racer_contestants, drag_racer_episodes, drag_family_data)
```


